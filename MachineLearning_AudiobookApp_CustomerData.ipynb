{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d1021c6",
   "metadata": {},
   "source": [
    "# Business Case: Audiobook App Buyer Behaviour\n",
    "## Machine Learning Models\n",
    "\n",
    "Below I create a machine learning algorithm based on our available data that can predict if a customer will buy again from an Audiobook company.Each customer in the database has made a purchase at least once, that's why he/she is in the database. \n",
    "\n",
    "It is ineffective to spend money on marketting to customers with a low proabbility of making additional purchaces. Through targettted marketting campaings catering to customers with higher probabilities of making additional purchaces, the company can prevent the ineffective spending of its marketing budget. Moreover, this model can identify the most important metrics that lead to returning customers, thereby identifying opportunities for growth.\n",
    "\n",
    "The pre-processed data contains the following variables: Book length in mins_avg (average of all purchases), Book length in minutes_sum (sum of all purchases), Price Paid_avg (average of all purchases), Price paid_sum (sum of all purchases), Review (a Boolean variable), Review (out of 10), Total minutes listened, Completion (from 0 to 1), Support requests (number), and Last visited minus purchase date (in days).\n",
    "\n",
    "The targets are a Boolean variable (so 0, or 1). We are taking a period of 2 years in our inputs, and the next 6 months as targets. Therefore the model predicts if: based on the last 2 years of activity and engagement, a customer will convert in the next 6 months.\n",
    "\n",
    "\n",
    "## Machine learning algorithm\n",
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59de1655",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887979f8",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90284c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temporary variable npz, to store each of the three Audiobooks datasets\n",
    "# training data\n",
    "npz = np.load('Audiobooks_data_train.npz')\n",
    "# extract the inputs and ensure all are floats\n",
    "train_inputs = npz['inputs'].astype(np.float)\n",
    "# extract targets and ensure all are integer (for one-hot encoding)\n",
    "train_targets = npz['targets'].astype(np.int)\n",
    "\n",
    "# validation data \n",
    "npz = np.load('Audiobooks_data_validation.npz')\n",
    "validation_inputs, validation_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)\n",
    "\n",
    "# testing data\n",
    "npz = np.load('Audiobooks_data_test.npz')\n",
    "test_inputs, test_targets = npz['inputs'].astype(np.float), npz['targets'].astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d26da3",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "- outline\n",
    "- optimizers\n",
    "- loss\n",
    "- early stopping\n",
    "- training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc79c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input and output sizes\n",
    "input_size = 10\n",
    "output_size = 2\n",
    "# Use same hidden layer size for both hidden layers. Not a necessity.\n",
    "hidden_layer_size = 50\n",
    "    \n",
    "# define how the model will look like\n",
    "model = tf.keras.Sequential([\n",
    "    # tf.keras.layers.Dense is basically implementing: output = activation(dot(input, weight) + bias)\n",
    "    # most important argumenrts here are hidden_layer_size and the activation function\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 1st hidden layer\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'), # 2nd hidden layer\n",
    "    # make sure to activate last layer with softmax\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax') # output layer\n",
    "])\n",
    "\n",
    "\n",
    "### Choose optimizer, loss function and metrics after each itteration\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917cbc20",
   "metadata": {},
   "source": [
    "### Trainging the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70523647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the batch size\n",
    "batch_size = 100\n",
    "\n",
    "# set a maximum number of training epochs\n",
    "max_epochs = 100\n",
    "\n",
    "# set an early stopping mechanism\n",
    "# let's set patience=2, to be a bit tolerant against random validation loss increases\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ea9e09",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304576b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_inputs, # train inputs\n",
    "          train_targets, # train targets\n",
    "          batch_size=batch_size, # batch size\n",
    "          epochs=max_epochs, # epochs that we will train for (assuming early stopping doesn't kick in)\n",
    "          # callbacks are functions called by a task when a task is completed\n",
    "          # task here is to check if val_loss is increasing\n",
    "          callbacks=[early_stopping], # early stopping\n",
    "          validation_data=(validation_inputs, validation_targets), # validation data\n",
    "          verbose = 2 # making sure we get enough information about the training process\n",
    "          )  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6affbab1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Test the model\n",
    "\n",
    "Test the final prediction power of our model by running it on the test dataset that the algorithm has not seen before. Only test once completely done with adjusting your model. Adjustment of model after testingleads to overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bc1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_inputs, test_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb25b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTest loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0a6f26",
   "metadata": {},
   "source": [
    "The final test accuracy should be roughly around 91%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
